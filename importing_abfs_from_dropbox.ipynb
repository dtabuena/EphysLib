{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "importing_abfs_from_dropbox.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/EphysLib/blob/main/importing_abfs_from_dropbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########## Importing ABFs From DropBox ################\n",
        "\n",
        "def get_drobox_folder(link, new_filename):\n",
        "    'Download a folder from dropbox and unzip'\n",
        "\n",
        "    suffix_start = new_filename.find(\".zip\")\n",
        "    new_filename_stripped = new_filename[0:suffix_start]\n",
        "    zipped_file_path = \"/content/\"+new_filename\n",
        "    unzipped_file_path = \"/content/\"+new_filename_stripped\n",
        "    if not( os.path.exists(zipped_file_path)):\n",
        "        !wget -O $new_filename $link    # download with new name\n",
        "    # if not( os.path.exists(new_filename_stripped)):\n",
        "    !echo A | unzip $zipped_file_path -d $unzipped_file_path \n",
        "    return new_filename_stripped\n"
      ],
      "metadata": {
        "id": "GAdhTTuFIZhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sub_files(rootdir):\n",
        "    'Recursively search subfolders and return a list of all files'\n",
        "    file_list =[]\n",
        "    for rootdir, dirs, files in os.walk(file_loc): \n",
        "            file_list.extend([os.path.join(rootdir,f) for f in files])\n",
        "    return file_list\n"
      ],
      "metadata": {
        "id": "c7GBedBpIYk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meng4TbgwKVc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def catalogue_recs(file_loc,cell_id_order):\n",
        "    'Read metadata from abf files stored in chosen folder and assigns'\n",
        "    'them to a dataframe for further processing. All further abf analyses'\n",
        "    'read files from this df and report values in the df.'\n",
        "\n",
        "    file_list = get_sub_files(file_loc)\n",
        "    # file_list = [file_loc+'/'+f for f in file_list]\n",
        "\n",
        "    file_list=[f for f in file_list if '.abf' in f]\n",
        "\n",
        "    abf_recordings_df = pd.DataFrame(data = file_list, columns=['file_name'])    \n",
        "    abf_recordings_df = abf_recordings_df.set_index('file_name')\n",
        "\n",
        "    abf_recordings_df['Recording_name'] = None\n",
        "    abf_recordings_df['cell_id'] = None\n",
        "    for c in cell_id_order:\n",
        "        abf_recordings_df[c] = None\n",
        "    \n",
        "    abf_recordings_df[\"protocol\"] = None\n",
        "    abf_recordings_df[\"abf_timestamp\"] = None\n",
        "    abf_recordings_df[\"channelList\"] = None\n",
        "\n",
        "\n",
        "    for r in np.arange(len(abf_recordings_df)):\n",
        "        row_filename = abf_recordings_df.index[r]\n",
        "        if '.sta' in row_filename:\n",
        "            continue\n",
        "        base_name = os.path.basename(row_filename)\n",
        "        abf_recordings_df.loc[row_filename,'Recording_name'] = base_name\n",
        "        split_words = base_name.split('_')\n",
        "        re_code = ['_'+split_words[i] for i in range(len(cell_id_order))]\n",
        "        re_code = ''.join(re_code)[1:]\n",
        "        abf_recordings_df.loc[row_filename,'cell_id'] = re_code\n",
        "        for ci in range(len(cell_id_order)):\n",
        "            abf_recordings_df.loc[row_filename,cell_id_order[ci]] = split_words[ci]\n",
        "\n",
        "        abf = pyabf.ABF(row_filename)\n",
        "        abf_recordings_df.loc[row_filename,'protocol'] = abf.protocol\n",
        "        abf_recordings_df.at[row_filename,'channelList'] = abf.channelList\n",
        "        abf_recordings_df.at[row_filename,'abf_timestamp'] = abf.abfDateTimeString\n",
        "    abf_recordings_df.sort_values('file_name',inplace=True)\n",
        "    protocol_set = list(set(abf_recordings_df['protocol']))\n",
        "    return abf_recordings_df, protocol_set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cell_prot_lut(abf_recordings_df,protocol_set,csv_name='Protocol_LUT',download=True):\n",
        "    if '.csv' not in csv_name: csv_name =csv_name+'.csv'\n",
        "    file_index = list(abf_recordings_df.index)\n",
        "    \n",
        "    cell_index = list(set(abf_recordings_df['cell_id']))\n",
        "\n",
        "    lut_df = pd.DataFrame(index=cell_index, columns=protocol_set)\n",
        "    \n",
        "\n",
        "    for f in file_index:\n",
        "        col_pos = abf_recordings_df.loc[f,'protocol']\n",
        "        row_pos = abf_recordings_df.loc[f,'cell_id']\n",
        "        lut_df.at[row_pos,col_pos] = os.path.basename(f)\n",
        "    if download:\n",
        "        lut_df.to_csv(csv_name)\n",
        "        files.download(csv_name)\n",
        "    return lut_df"
      ],
      "metadata": {
        "id": "K4nUf5cEIXT0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}