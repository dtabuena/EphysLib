{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_Main.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/EphysLib/blob/main/_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'Get Standard Modules'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import os\n",
        "from scipy.signal import butter,filtfilt\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import warnings\n",
        "import shutil\n",
        "from google.colab import files\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "clear_output(wait=False)"
      ],
      "metadata": {
        "id": "JB3cLtpu5iXZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try: shutil.rmtree('/content/EphysLib')\n",
        "except: None\n",
        "\n",
        "\"run dtabuena's ephys notebooks\"\n",
        "!git clone https://github.com/dtabuena/EphysLib\n",
        "\n",
        "to_import = ['ABF_Quality_Control.ipynb',\n",
        "          'Basic_Ephys.ipynb',\n",
        "          'Firing_Rate_Gain.ipynb',\n",
        "          'Simple_ABF_tools.ipynb',\n",
        "          'IV_analyzer.ipynb',\n",
        "          'membrane_analyzer.ipynb',\n",
        "          'analyze_rheobase.ipynb',\n",
        "          'fun_math.ipynb',\n",
        "          'importing_abfs_from_dropbox.ipynb',\n",
        "          'input_resistance_analyzer.ipynb',\n",
        "          'latencey_analyzer.ipynb',\n",
        "          'QC_recoding_dataframe.ipynb'\n",
        "            ]\n",
        "\n",
        "for i in to_import:\n",
        "    f = '/content/EphysLib/' + i\n",
        "    %run $f\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4lZ-pjFGrf_",
        "outputId": "dcacdeb3-cbbb-4650-a040-e2bf0ea54d3e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EphysLib'...\n",
            "remote: Enumerating objects: 181, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 181 (delta 58), reused 29 (delta 29), pack-reused 94\u001b[K\n",
            "Receiving objects: 100% (181/181), 180.10 KiB | 20.01 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyabf in /usr/local/lib/python3.7/dist-packages (2.3.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pyabf) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from pyabf) (1.21.6)\n",
            "Requirement already satisfied: pytest>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from pyabf) (3.6.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pyabf) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pyabf) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pyabf) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pyabf) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pyabf) (4.1.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (1.15.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (22.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (57.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (8.14.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'Import and catalog source data'\n",
        "'RNF182 Dropbox'\n",
        "data_source = \"https://www.dropbox.com/sh/n9t8p257wnzlijk/AAC9Z36JodisyZjnM3mkJC3Xa?dl=0\"\n",
        "file_loc = get_drobox_folder(data_source, 'my_ephys_data.zip')\n",
        "clear_output(wait=False)\n",
        "file_naming_scheme = ['Rec_date','Virus','GenoType','Sex','Age','Slice_Num','Cell_num','Cell_Type']\n",
        "abf_recordings_df,protocol_set = catalogue_recs(file_loc,file_naming_scheme)\n",
        "print('Protocol_Names:')\n",
        "_ = [print(p) for p in protocol_set]"
      ],
      "metadata": {
        "id": "MYTtLS5v5V-J",
        "outputId": "73166dcc-1c2a-4f29-fb46-57714de9817c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Protocol_Names:\n",
            "VC - Multi IV - 150ms\n",
            "IC - Rheobase\n",
            "IC - Gain - D50pA\n",
            "IC - Sag - D50pA\n",
            "IC - R input\n",
            "VC - MemTest-10ms-160ms\n",
            "VC - 3min GapFree\n",
            "IC - Latentcy 800pA-1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VC_prot = ['VC - MemTest-10ms-160ms',\n",
        "           'VC - Multi IV - 150ms',\n",
        "           'VC - 3min GapFree',\n",
        "           'VC - Spontaneous-3min-(MT)']\n",
        "IC_prot = ['IC - Gain - D20pA',\n",
        "           'IC - Gain - D50pA',\n",
        "           'IC - Rheobase',\n",
        "           'IC - R input',\n",
        "           'IC - Latentcy 800pA-1s']\n",
        "\n",
        "abf_recordings_df, _ = purge_wrong_clamp(abf_recordings_df,VC_prot,IC_prot)"
      ],
      "metadata": {
        "id": "7A4t8U0ea33E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analysis_iterator(abf_recordings_df,func_dict,arg_dict):\n",
        "    problem_recs = []\n",
        "    def init_col_object(df,name): \n",
        "        df[name] = None\n",
        "        df[name] = df[name].astype(object)\n",
        "        return df\n",
        "\n",
        "    for file_name in tqdm(abf_recordings_df.index):\n",
        "        abf = abf_or_name(file_name)\n",
        "        prot_name = abf.protocol\n",
        "\n",
        "\n",
        "        # check for keyed protocol\n",
        "        if prot_name not in func_dict.keys():\n",
        "            # print('unknown protocol(func): ',  prot_name)\n",
        "            continue\n",
        "        if prot_name not in arg_dict.keys():\n",
        "            # print('unknown protocol(args): ',  prot_name)\n",
        "            continue\n",
        "\n",
        "\n",
        "        try:\n",
        "            analyzer_func = func_dict[prot_name]  # get analyzer from dict\n",
        "            args_for_analyzer =  [abf] + arg_dict[prot_name] # get args for analyzer from dict\n",
        "            results = analyzer_func(*args_for_analyzer) # run analyzer\n",
        "            for k in results.keys():\n",
        "\n",
        "                # New Col?\n",
        "                cols = abf_recordings_df.columns\n",
        "                if k not in cols:\n",
        "                    abf_recordings_df = init_col_object(abf_recordings_df,k)\n",
        "                abf_recordings_df.at[file_name,k] = results[k]\n",
        "        except: \n",
        "            print('error on: ' ,file_name)\n",
        "            problem_recs.append(file_name)\n",
        "\n",
        "    return abf_recordings_df, problem_recs\n",
        "\n",
        "\n",
        "spike_args =  {'spike_thresh':20, 'high_dv_thresh': 25,'low_dv_thresh': -5,'window_ms': 2}\n",
        "\n",
        "func_dict = {}\n",
        "arg_dict = {}\n",
        "\n",
        "func_dict['IC - Rheobase']= rheobase_analyzer\n",
        "arg_dict['IC - Rheobase'] = [spike_args, False, False, False]  # [spike_args, to_plot, verbose, force_singlespike]\n",
        "\n",
        "func_dict['IC - Gain - D20pA']= gain_analyzer\n",
        "arg_dict['IC - Gain - D20pA']= [spike_args, 0.8, 0]  # [spike_args, to_plot, verbose, force_singlespike]\n",
        "func_dict['IC - Gain - D50pA']= func_dict['IC - Gain - D20pA'] \n",
        "arg_dict['IC - Gain - D50pA']= arg_dict['IC - Gain - D20pA']\n",
        "\n",
        "func_dict['VC - MemTest-10ms-160ms']= membrane_analyzer\n",
        "arg_dict['VC - MemTest-10ms-160ms']= [False, False, ['Ra', 'Rm', 'Cm', 'tau',\t'Cmq',\t'Cmf',\t'Cmqf', 'Cm_pc']]  # [to_plot, verbose]\n",
        "\n",
        "func_dict['IC - Latentcy 800pA-1s']= latencey_analyzer \n",
        "arg_dict['IC - Latentcy 800pA-1s']= [spike_args, False]  # [spike_args, to_plot]\n",
        "\n",
        "func_dict['IC - Latentcy 800pA-1s']= latencey_analyzer \n",
        "arg_dict['IC - Latentcy 800pA-1s']= [spike_args, False]  # [spike_args, to_plot]\n",
        "\n",
        "func_dict['IC - R input']= input_resistance_analyzer \n",
        "arg_dict['IC - R input']= [[-30, 10] ,False]  # [dVm_limits, to_plot]\n",
        "\n",
        "\n",
        "func_dict['VC - Multi IV - 150ms'] = IV_analyzer\n",
        "arg_dict['VC - Multi IV - 150ms']= [{'IV_Early':(16.5, 30),'IV_Steady_State':(100,120)} ,False]  # [measure_windows, to_plot]\n",
        "\n",
        "\n",
        "abf_recordings_df, problem_recs = analysis_iterator(abf_recordings_df,func_dict,arg_dict)\n",
        "print(problem_recs)\n",
        "\n",
        "abf_recordings_df.to_csv('test.csv')\n",
        "files.download('test.csv')"
      ],
      "metadata": {
        "id": "CANQTWscKMtA",
        "outputId": "9e794b4e-9b12-4729-abe6-cee5e0df9100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 57/226 [00:22<00:37,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error on:  my_ephys_data/2022_08_12_RNF182/2022x08x12_RNF182_E4KI_F_P251_s002_c006_CA3xPOS_0006.abf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 80/226 [00:31<00:47,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ap_stats_failed:  ABF (v2.9) with 2 channels (mV, pA), sampled at 10.0 kHz, containing 4 sweeps, having no tags, with a total length of 0.73 minutes, recorded with protocol \"IC - Rheobase\".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [01:30<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['my_ephys_data/2022_08_12_RNF182/2022x08x12_RNF182_E4KI_F_P251_s002_c006_CA3xPOS_0006.abf']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_91dd689f-480f-454a-a908-5e6ea4b00452\", \"test.csv\", 120876)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cell_sorting(abf_recordings_df):\n",
        "\n",
        "    unique_cells = list(set(abf_recordings_df['cell_id']))\n",
        "    unique_cells.sort()\n",
        "    transfer_cols = [c for c in abf_recordings_df.columns if 'cell_id' not in c]\n",
        "    cell_df = pd.DataFrame(index=list(unique_cells),columns = transfer_cols)\n",
        "    \n",
        "\n",
        "    for cell in cell_df.index:\n",
        "        match = [cell in r for r in abf_recordings_df['cell_id']]\n",
        "        for col in transfer_cols:\n",
        "            match_values = list(abf_recordings_df[match][col])\n",
        "            # print('col', col)\n",
        "            # print(match_values)\n",
        "\n",
        "            cell_df.at[cell,col] = match_values\n",
        "    return cell_df\n",
        "\n",
        "\n",
        "cell_df = cell_sorting(abf_recordings_df)\n",
        "\n",
        "def cell_consolidation(cell_df,list_types,any_types,average_types = True):\n",
        "    cell_df_con = cell_df.copy()\n",
        "    explicit_cols = ['IV_Early','IV_Steady_State']\n",
        "\n",
        "    if average_types:\n",
        "        average_types = [c for c in cell_df_con.columns if c not in any_types and c not in list_types and c not in explicit_cols]\n",
        "        \n",
        "        # print('average_types',average_types)\n",
        "\n",
        "\n",
        "\n",
        "    for cell in cell_df_con.index:\n",
        "        for col in list_types:\n",
        "            'do nothing, keep the list'\n",
        "        for col in any_types:\n",
        "            'they are all the same take the first'\n",
        "            cell_df_con.at[cell,col] = cell_df_con.at[cell,col][0]\n",
        "\n",
        "        for col in average_types:\n",
        "            multi_vals = cell_df_con.loc[cell,col]\n",
        "            try:\n",
        "                multi_vals = [v for v in multi_vals if v is not None]\n",
        "                single_val = np.nanmean(multi_vals,0)\n",
        "                cell_df_con.at[cell,col] = single_val\n",
        "                # print(single_val)\n",
        "            except: 'Just keep going None'\n",
        "        \n",
        "\n",
        "    # explicitly defined consolidation\n",
        "    for cell in cell_df_con.index:\n",
        "        try:\n",
        "            multi_vals = cell_df_con.loc[cell,'IV_Early']\n",
        "            multi_vals = [v for v in multi_vals if v is not None]            \n",
        "            v_stim = [  mv['V_stim'] for mv in  multi_vals ]\n",
        "            peak_vals = [  mv['I_peak'] for mv in  multi_vals ]\n",
        "            if len(v_stim)>1:\n",
        "                v_stim_set = [v for v in [vl for vl in  v_stim ] ]\n",
        "                print(v_stim_set)\n",
        "\n",
        "        except:\n",
        "            if np.isnan(multi_vals):\n",
        "                multi_vals = None\n",
        "            \n",
        "\n",
        "        # print(multi_vals)\n",
        "\n",
        "    return cell_df_con\n",
        "\n",
        "list_types = ['Recording_name','protocol','abf_timestamp', 'channelList']\n",
        "any_types = ['Rec_date',\t'Virus',\t'GenoType',\t'Sex',\t'Age',\t'Slice_Num',\t'Cell_num',\t'Cell_Type']\n",
        "\n",
        "\n",
        "cell_df_con = cell_consolidation(cell_df,list_types,any_types)\n",
        "cell_df_con.to_csv('cell_df_con.csv')\n",
        "files.download('cell_df_con.csv')"
      ],
      "metadata": {
        "id": "GtJUI1kFl0eJ",
        "outputId": "8d7aec70-4f50-4f4f-dd9c-cc6aaad819eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-130], [-130, -120, -110, -100, -90, -80, -70, -60, -50, -40, -30, -20, -10, 0, 10]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3fe9f8ea-d324-4176-902f-09cb353057b9\", \"cell_df_con.csv\", 77216)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdDOzAmJnfqB"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}